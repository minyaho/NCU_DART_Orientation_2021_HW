{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NCU_DART_O2021_W5_HW.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPVW8DW-7ler",
        "outputId": "1b96cf2c-07f0-4cb3-e7fc-d9a5c1f5e39f"
      },
      "source": [
        "!pip install dgl-cu110 -f https://data.dgl.ai/wheels/repo.html"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://data.dgl.ai/wheels/repo.html\n",
            "Collecting dgl-cu110\n",
            "  Downloading https://data.dgl.ai/wheels/dgl_cu110-0.7.0-cp37-cp37m-manylinux1_x86_64.whl (142.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 142.5 MB 50 kB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.7/dist-packages (from dgl-cu110) (2.5.1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu110) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu110) (1.19.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu110) (2.23.0)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.1->dgl-cu110) (4.4.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu110) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu110) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu110) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu110) (3.0.4)\n",
            "Installing collected packages: dgl-cu110\n",
            "Successfully installed dgl-cu110-0.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8Vvlr9M7Rmz",
        "outputId": "8fb3f033-2666-44d7-ceae-9874ca0aae7e"
      },
      "source": [
        "import dgl\n",
        "import dgl.data\n",
        "from dgl.nn import GraphConv\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using backend: pytorch\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spX35aZ-7WA1",
        "outputId": "e6f78dc3-68c1-40b6-e922-af827899d639"
      },
      "source": [
        "import dgl.data\n",
        "\n",
        "dataset = dgl.data.CoraGraphDataset()\n",
        "\n",
        "g = dataset[0]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  NumNodes: 2708\n",
            "  NumEdges: 10556\n",
            "  NumFeats: 1433\n",
            "  NumClasses: 7\n",
            "  NumTrainingSamples: 140\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "Done loading data from cached files.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Kf71QfJ7X_u"
      },
      "source": [
        "class GCN(nn.Module):\n",
        "    def __init__(self, in_feats, h_feats, num_classes):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GraphConv(in_feats, h_feats)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = GraphConv(h_feats, num_classes)\n",
        "\n",
        "    def forward(self, g, in_feats):\n",
        "        h = self.conv1(g, in_feats)\n",
        "        h = self.relu(h)\n",
        "        h = self.conv2(g, h)\n",
        "        return h"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYc68jnP7ZmC"
      },
      "source": [
        "def train(g, model):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "    cross_entropy = torch.nn.CrossEntropyLoss()\n",
        "    best_val_acc = 0\n",
        "    best_test_acc = 0\n",
        "\n",
        "    features = g.ndata['feat']\n",
        "    labels = g.ndata['label']\n",
        "    train_mask = g.ndata['train_mask']\n",
        "    val_mask = g.ndata['val_mask']\n",
        "    test_mask = g.ndata['test_mask']\n",
        "\n",
        "    for e in range(100):\n",
        "        logits = model(g, features)\n",
        "\n",
        "        pred = logits.argmax(1)\n",
        "\n",
        "        loss  = cross_entropy(logits[train_mask], labels[train_mask])\n",
        "\n",
        "        train_acc = (pred[train_mask] == labels[train_mask]).float().mean()\n",
        "        val_acc = (pred[val_mask] == labels[val_mask]).float().mean()\n",
        "        test_acc = (pred[test_mask] == labels[test_mask]).float().mean()\n",
        "\n",
        "        if best_val_acc < val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            best_test_acc = test_acc\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if e % 5 == 0:\n",
        "            print('In epoch {}, loss: {:.3f}, val acc: {:.3f} (best {:.3f}), test acc: {:.3f} (best {:.3f})'.format(\n",
        "                e, loss, val_acc, best_val_acc, test_acc, best_test_acc))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmbD5Oqa7cF_",
        "outputId": "55a035a6-bdae-4145-f96d-9d01237706cd"
      },
      "source": [
        "model = GCN(g.ndata['feat'].shape[1],\n",
        "           16, \n",
        "           dataset.num_classes)\n",
        "train(g, model)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "In epoch 0, loss: 1.946, val acc: 0.136 (best 0.136), test acc: 0.138 (best 0.138)\n",
            "In epoch 5, loss: 1.888, val acc: 0.366 (best 0.416), test acc: 0.374 (best 0.420)\n",
            "In epoch 10, loss: 1.805, val acc: 0.404 (best 0.416), test acc: 0.417 (best 0.420)\n",
            "In epoch 15, loss: 1.701, val acc: 0.512 (best 0.512), test acc: 0.511 (best 0.511)\n",
            "In epoch 20, loss: 1.577, val acc: 0.558 (best 0.558), test acc: 0.552 (best 0.552)\n",
            "In epoch 25, loss: 1.436, val acc: 0.600 (best 0.600), test acc: 0.604 (best 0.604)\n",
            "In epoch 30, loss: 1.281, val acc: 0.666 (best 0.666), test acc: 0.664 (best 0.664)\n",
            "In epoch 35, loss: 1.117, val acc: 0.690 (best 0.690), test acc: 0.690 (best 0.690)\n",
            "In epoch 40, loss: 0.952, val acc: 0.714 (best 0.714), test acc: 0.729 (best 0.729)\n",
            "In epoch 45, loss: 0.794, val acc: 0.738 (best 0.738), test acc: 0.742 (best 0.742)\n",
            "In epoch 50, loss: 0.649, val acc: 0.746 (best 0.746), test acc: 0.750 (best 0.746)\n",
            "In epoch 55, loss: 0.524, val acc: 0.760 (best 0.760), test acc: 0.756 (best 0.756)\n",
            "In epoch 60, loss: 0.420, val acc: 0.766 (best 0.766), test acc: 0.758 (best 0.755)\n",
            "In epoch 65, loss: 0.336, val acc: 0.766 (best 0.768), test acc: 0.761 (best 0.760)\n",
            "In epoch 70, loss: 0.271, val acc: 0.766 (best 0.768), test acc: 0.768 (best 0.760)\n",
            "In epoch 75, loss: 0.219, val acc: 0.762 (best 0.768), test acc: 0.778 (best 0.760)\n",
            "In epoch 80, loss: 0.179, val acc: 0.762 (best 0.768), test acc: 0.780 (best 0.760)\n",
            "In epoch 85, loss: 0.148, val acc: 0.768 (best 0.768), test acc: 0.780 (best 0.760)\n",
            "In epoch 90, loss: 0.124, val acc: 0.778 (best 0.778), test acc: 0.780 (best 0.780)\n",
            "In epoch 95, loss: 0.105, val acc: 0.778 (best 0.778), test acc: 0.780 (best 0.780)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}